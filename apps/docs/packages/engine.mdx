---
title: "@novai/engine"
description: "Core game engine package for AI-powered tabletop RPG experiences"
---

# @novai/engine

The core game engine package that provides AI-powered tabletop RPG functionality. This package contains the main services and types for running interactive narrative games.

## Installation

```bash
npm install @novai/engine
# or
pnpm add @novai/engine
```

## Quick Start

```typescript
import { GameEngineService } from '@novai/engine';

const llmConfig = {
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  model: 'gpt-4'
};

const engine = new GameEngineService(llmConfig);

// Create a new game
const gameState = await engine.createNewGame('baldurs-gate-3', 'Player Name');

// Process player input
const response = await engine.processGameRequest({
  gameState,
  playerInput: 'I want to explore the tavern',
  context: { timeOfDay: 'evening' }
});
```

## Core Components

### GameEngineService

The main orchestrator for game operations.

```typescript
export class GameEngineService {
  constructor(llmConfig: LLMConfig, campaignsPath?: string)
  
  async processGameRequest(request: GameRequest): Promise<GameResponse>
  async createNewGame(campaignId: string, playerName: string): Promise<GameState>
}
```

### LLMService

Handles communication with language models.

```typescript
export class LLMService {
  constructor(config: LLMConfig)
  
  async callLLM(
    prompt: string,
    memory: string[],
    temperature: number = 0.7
  ): Promise<string>
}
```

### CampaignService

Manages campaign data and metadata.

```typescript
export class CampaignService {
  constructor(campaignsPath?: string)
  
  async loadCampaign(campaignId: string): Promise<Campaign>
  async getCampaignIntro(campaignId: string): Promise<string>
}
```

## Types

### Game State

```typescript
interface GameState {
  id: string;
  campaignId: string;
  playerName: string;
  currentLocation: string;
  companions: string[];
  inventory: string[];
  stats: Record<string, number>;
  choices: string[];
  narrative: NarrativeEntry[];
  metadata?: Record<string, unknown>;
}

interface NarrativeEntry {
  timestamp: string;
  content: string;
  type: 'narration' | 'choice' | 'combat' | 'stat-check';
}
```

### Game Requests and Responses

```typescript
interface GameRequest {
  gameState: GameState;
  playerInput: string;
  context?: Record<string, unknown>;
}

interface GameResponse {
  narration: string;
  choices?: string[];
  statCheck?: {
    stat: string;
    difficulty: number;
    result: number;
    success: boolean;
  };
  combat?: {
    enemies: string[];
    playerHealth: number;
    enemyHealth: Record<string, number>;
  };
  updatedGameState: GameState;
}
```

### LLM Configuration

```typescript
type LLMProvider = 'openai' | 'local';

interface LLMConfig {
  provider: LLMProvider;
  apiKey?: string;
  model?: string;
  baseUrl?: string;
}
```

### Campaign Types

```typescript
interface Campaign {
  id: string;
  name: string;
  description: string;
  ruleset: string;
  intro: string;
  companions: Companion[];
  locations: Location[];
  plot: PlotPoint[];
}

interface Companion {
  id: string;
  name: string;
  description: string;
  stats?: Record<string, number>;
}

interface Location {
  id: string;
  name: string;
  description: string;
  connections?: string[];
}

interface PlotPoint {
  id: string;
  title: string;
  description: string;
  requirements?: string[];
}
```

## Usage Examples

### Basic Game Loop

```typescript
import { GameEngineService } from '@novai/engine';

const engine = new GameEngineService({
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY
});

// Start a new game
let gameState = await engine.createNewGame('my-campaign', 'Adventurer');

// Game loop
async function gameLoop() {
  const playerInput = await getUserInput();
  
  const response = await engine.processGameRequest({
    gameState,
    playerInput,
    context: { timeOfDay: 'morning' }
  });
  
  // Update game state
  gameState = response.updatedGameState;
  
  // Display response
  displayNarration(response.narration);
  
  if (response.choices) {
    displayChoices(response.choices);
  }
  
  if (response.statCheck) {
    handleStatCheck(response.statCheck);
  }
  
  if (response.combat) {
    handleCombat(response.combat);
  }
}
```

### Custom LLM Provider

```typescript
import { LLMService, LLMConfig } from '@novai/engine';

class CustomLLMService extends LLMService {
  async callLLM(
    prompt: string,
    memory: string[],
    temperature: number
  ): Promise<string> {
    // Custom implementation
    const response = await fetch('https://my-llm-api.com/generate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        prompt,
        memory,
        temperature
      })
    });
    
    const data = await response.json();
    return data.response;
  }
}

const customLLM = new CustomLLMService({
  provider: 'custom',
  baseUrl: 'https://my-llm-api.com'
});
```

### Campaign Management

```typescript
import { CampaignService } from '@novai/engine';

const campaignService = new CampaignService('./campaigns');

// Load a campaign
const campaign = await campaignService.loadCampaign('baldurs-gate-3');

// Get campaign introduction
const intro = await campaignService.getCampaignIntro('baldurs-gate-3');

console.log(`Campaign: ${campaign.name}`);
console.log(`Description: ${campaign.description}`);
console.log(`Companions: ${campaign.companions.map(c => c.name).join(', ')}`);
```

### State Persistence

```typescript
import { GameState } from '@novai/engine';

// Save game state
async function saveGame(gameState: GameState): Promise<void> {
  const stateData = JSON.stringify(gameState, null, 2);
  await fs.writeFile(`saves/${gameState.id}.json`, stateData);
}

// Load game state
async function loadGame(gameId: string): Promise<GameState> {
  const stateData = await fs.readFile(`saves/${gameId}.json`, 'utf8');
  return JSON.parse(stateData);
}

// Usage
const gameState = await engine.createNewGame('campaign', 'Player');
await saveGame(gameState);

// Later...
const loadedState = await loadGame(gameState.id);
const response = await engine.processGameRequest({
  gameState: loadedState,
  playerInput: 'Continue my adventure'
});
```

## Error Handling

### LLM Errors

```typescript
try {
  const response = await engine.processGameRequest(request);
  // Handle successful response
} catch (error) {
  if (error.message.includes('API')) {
    console.error('LLM API error:', error.message);
    // Handle API errors
  } else if (error.message.includes('campaign')) {
    console.error('Campaign error:', error.message);
    // Handle campaign errors
  } else {
    console.error('Unexpected error:', error.message);
    // Handle other errors
  }
}
```

### State Validation

```typescript
import { GameStateSchema } from '@novai/engine';

function validateGameState(state: unknown): GameState {
  try {
    return GameStateSchema.parse(state);
  } catch (error) {
    throw new Error(`Invalid game state: ${error.message}`);
  }
}
```

## Configuration

### Environment Variables

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key

# Local LLM Configuration
LOCAL_LLM_URL=http://localhost:11434
LOCAL_LLM_MODEL=llama2:7b

# Campaign Path
CAMPAIGNS_PATH=./campaigns
```

### LLM Provider Setup

#### OpenAI

```typescript
const openaiConfig: LLMConfig = {
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  model: 'gpt-4', // or 'gpt-3.5-turbo'
  baseUrl: 'https://api.openai.com/v1'
};
```

#### Local Models (Ollama)

```typescript
const localConfig: LLMConfig = {
  provider: 'local',
  baseUrl: 'http://localhost:11434',
  model: 'llama2:7b'
};
```

## Performance

### Memory Management

The engine uses a sliding window approach for narrative memory:

```typescript
// Get last 5 narrative entries for context
const memory = gameState.narrative
  .map(n => n.content)
  .slice(-5);
```

### Caching

```typescript
class CachedGameEngine extends GameEngineService {
  private cache = new Map<string, GameResponse>();
  
  async processGameRequest(request: GameRequest): Promise<GameResponse> {
    const cacheKey = this.generateCacheKey(request);
    
    if (this.cache.has(cacheKey)) {
      return this.cache.get(cacheKey)!;
    }
    
    const response = await super.processGameRequest(request);
    this.cache.set(cacheKey, response);
    
    return response;
  }
}
```

## Testing

### Unit Tests

```typescript
import { GameEngineService } from '@novai/engine';

describe('GameEngineService', () => {
  let engine: GameEngineService;
  
  beforeEach(() => {
    engine = new GameEngineService({
      provider: 'openai',
      apiKey: 'test-key'
    });
  });
  
  it('should create a new game', async () => {
    const gameState = await engine.createNewGame('test-campaign', 'Test Player');
    
    expect(gameState.playerName).toBe('Test Player');
    expect(gameState.campaignId).toBe('test-campaign');
  });
  
  it('should process game requests', async () => {
    const gameState = await engine.createNewGame('test-campaign', 'Test Player');
    
    const response = await engine.processGameRequest({
      gameState,
      playerInput: 'Hello world'
    });
    
    expect(response.narration).toBeDefined();
    expect(response.updatedGameState).toBeDefined();
  });
});
```

### Integration Tests

```typescript
describe('Game Engine Integration', () => {
  it('should handle a complete game session', async () => {
    const engine = new GameEngineService(testConfig);
    
    // Start game
    let gameState = await engine.createNewGame('test-campaign', 'Player');
    
    // Multiple interactions
    const inputs = [
      'I want to explore the tavern',
      'I talk to the bartender',
      'I order a drink'
    ];
    
    for (const input of inputs) {
      const response = await engine.processGameRequest({
        gameState,
        playerInput: input
      });
      
      gameState = response.updatedGameState;
      
      expect(response.narration).toBeDefined();
      expect(gameState.narrative.length).toBeGreaterThan(0);
    }
  });
});
```

## API Reference

### GameEngineService

#### Constructor

```typescript
constructor(llmConfig: LLMConfig, campaignsPath?: string)
```

#### Methods

```typescript
async processGameRequest(request: GameRequest): Promise<GameResponse>
async createNewGame(campaignId: string, playerName: string): Promise<GameState>
```

### LLMService

#### Constructor

```typescript
constructor(config: LLMConfig)
```

#### Methods

```typescript
async callLLM(prompt: string, memory: string[], temperature?: number): Promise<string>
```

### CampaignService

#### Constructor

```typescript
constructor(campaignsPath?: string)
```

#### Methods

```typescript
async loadCampaign(campaignId: string): Promise<Campaign>
async getCampaignIntro(campaignId: string): Promise<string>
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## License

MIT License - see LICENSE file for details. 